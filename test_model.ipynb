{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#from pygame import mixer # Load the required library\n",
    "import requests\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "print (cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network model and network weights from files\n",
    "def read_model(network_path):\n",
    "    exit_ifnex(network_path)\n",
    "    model = model_from_json(open(os.path.join(network_path, 'architecture.json')).read())\n",
    "    model.load_weights(os.path.join(network_path, 'weights.h5'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_index_of(array):\n",
    "    m = -1\n",
    "    index = -1\n",
    "    for i in range(len(array)):\n",
    "        if array[i] > m:\n",
    "            m = array[i]\n",
    "            index = i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_ifnex(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(directory, 'does not exist')\n",
    "        exit()\n",
    "def timestamp():\n",
    "    return int(round(time.time() * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural network\n",
    "model = read_model('../model2')\n",
    "headers={'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\"}\n",
    "width, height, channel = 300, 280, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "\n",
    "# Start with a halfway point between 0 and 1 of accumulated weight\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "\n",
    "# Manually set up our ROI for grabbing the hand.\n",
    "# Feel free to change these. I just chose the top right corner for filming.\n",
    "roi_top = 20\n",
    "roi_bottom = 300\n",
    "roi_right = 300\n",
    "roi_left = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accum_avg(frame, accumulated_weight):\n",
    "    '''\n",
    "    Given a frame and a previous accumulated weight, computed the weighted average of the image passed in.\n",
    "    '''\n",
    "    \n",
    "    # Grab the background\n",
    "    global background\n",
    "    \n",
    "    # For first time, create the background from a copy of the frame.\n",
    "    if background is None:\n",
    "        background = frame.copy().astype(\"float\")\n",
    "        return None\n",
    "\n",
    "    # compute weighted average, accumulate it and update the background\n",
    "    cv2.accumulateWeighted(frame, background, accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(frame, threshold=25):\n",
    "    global background\n",
    "    \n",
    "    # Calculates the Absolute Differentce between the backgroud and the passed in frame\n",
    "    diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
    "\n",
    "    # Apply a threshold to the image so we can grab the foreground\n",
    "    # We only need the threshold, so we will throw away the first item in the tuple with an underscore _\n",
    "    ret , thresholded = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Grab the external contours form the image\n",
    "    # Again, only grabbing what we need here and throwing away the rest\n",
    "    image, contours, hierarchy = cv2.findContours(thresholded.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If length of contours list is 0, then we didn't grab any contours!\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # Given the way we are using the program, the largest external contour should be the hand (largest by area)\n",
    "        # This will be our segment\n",
    "        hand_segment = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Return both the hand segment and the thresholded hand image\n",
    "        return (thresholded, hand_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from threading import *\n",
    "from pygame import mixer # Load the required library\n",
    "j=0\n",
    "url=\"https://translate.google.com/translate_tts\"\n",
    "text=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class play(Thread):\n",
    "    \n",
    "    def run(self):\n",
    "        global text\n",
    "        global j\n",
    "        while True:\n",
    "            if len(text)>10:\n",
    "                params={'ie':'UTF-8','q': text,'tl': 'en','client': 'gtx'}\n",
    "                r= requests.get(url,params=params,headers=headers)\n",
    "                \n",
    "                with open(f\"thread{j}.mp3\",'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                mixer.init()\n",
    "                mixer.music.load(f\"thread{j}.mp3\")\n",
    "                mixer.music.play()\n",
    "                print(j)\n",
    "                \n",
    "                if j==0:\n",
    "                    if os.path.exists(\"thread1.mp3\"):\n",
    "                        os.remove(\"thread1.mp3\")\n",
    "                    j=1\n",
    "                else:\n",
    "                    if os.path.exists(\"thread0.mp3\"):\n",
    "                        os.remove(\"thread0.mp3\")\n",
    "                    j=0\n",
    "                print(text)\n",
    "                text=\"\"\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "1\n",
      "0\n",
      " what are how\n",
      "1\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-12-24afb1d489dd>\", line 20, in run\n",
      "    os.remove(\"thread1.mp3\")\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'thread1.mp3'\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-12-24afb1d489dd>\", line 11, in run\n",
      "    with open(f\"thread{j}.mp3\",'wb') as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'thread1.mp3'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "1\n",
      "0\n",
      " hi how how\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-12-24afb1d489dd>\", line 11, in run\n",
      "    with open(f\"thread{j}.mp3\",'wb') as f:\n",
      "PermissionError: [Errno 13] Permission denied: 'thread0.mp3'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "1\n",
      " you I hi hi\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "6\n",
      "1\n",
      "0\n",
      " I you you how\n",
      "1\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "1\n",
      " how fine fine\n",
      "0\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "thread=play()\n",
    "thread.start()\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "# capture settings\n",
    "time_between_capture_ms = 1000\n",
    "last_capture = timestamp()\n",
    "\n",
    "# Intialize a frame count\n",
    "num_frames = 0\n",
    "\n",
    "while True:\n",
    "    # get the current frame\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flip the frame so that it is not the mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # clone the frame\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    # Grab the ROI from the frame\n",
    "    roi = frame[roi_top:roi_bottom, roi_right:roi_left]\n",
    "\n",
    "    # Apply grayscale and blur to ROI\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "    # For the first 30 frames we will calculate the average of the background.\n",
    "    # We will tell the user while this is happening\n",
    "    if num_frames < 60:\n",
    "        calc_accum_avg(gray, accumulated_weight)\n",
    "        if num_frames <= 59:\n",
    "            cv2.putText(frame_copy, \"WAIT! GETTING BACKGROUND AVG.\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow(\"Finger Count\",frame_copy)\n",
    "            \n",
    "    else:\n",
    "        # now that we have the background, we can segment the hand.\n",
    "        \n",
    "        # segment the hand region\n",
    "        hand = segment(gray)\n",
    "\n",
    "        # First check if we were able to actually detect a hand\n",
    "        if hand is not None:\n",
    "            \n",
    "            # unpack\n",
    "            thresholded, hand_segment = hand\n",
    "\n",
    "            # Draw contours around hand segment\n",
    "            cv2.drawContours(frame_copy, [hand_segment + (roi_right, roi_top)], -1, (255, 0, 0),1)\n",
    "\n",
    "            # Count the fingers\n",
    "            #fingers = count_fingers(thresholded, hand_segment)\n",
    "            \n",
    "            # Display count\n",
    "            #cv2.putText(frame_copy, str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "            global text\n",
    "            # Also display the thresholded image\n",
    "            cv2.imshow(\"Thesholded\", thresholded)\n",
    "            image = cv2.resize(thresholded, (width, height))\n",
    "            image = img_to_array(image)\n",
    "            image = np.array(image, dtype=\"float\") / 255.0\n",
    "            image = image.reshape(1, width, height, channel)\n",
    "            if timestamp()-last_capture>time_between_capture_ms:\n",
    "                output = model.predict(image)\n",
    "                os.system('clear')\n",
    "\n",
    "                if max_index_of(output[0])==0:\n",
    "                    text=text+\" fine\" #paper\n",
    "                if max_index_of(output[0])==1:\n",
    "                    text=text+\" how\"\n",
    "                if max_index_of(output[0])==2:\n",
    "                    text=text+\" you\"\n",
    "                if max_index_of(output[0])==3:\n",
    "                    text=text+\" I\" #paper\n",
    "                if max_index_of(output[0])==4:\n",
    "                    text=text+\" are\"\n",
    "                if max_index_of(output[0])==5:\n",
    "                    text=text+\" hi\"\n",
    "                if max_index_of(output[0])==6:\n",
    "                    text=text #paper\n",
    "                if max_index_of(output[0])==7:\n",
    "                    text=text+\" am\"\n",
    "                print(max_index_of(output[0]))   \n",
    "                last_capture = timestamp()\n",
    "            \n",
    "    # Draw ROI Rectangle on frame copy\n",
    "    cv2.rectangle(frame_copy, (roi_left, roi_top), (roi_right, roi_bottom), (0,0,255), 5)\n",
    "\n",
    "    # increment the number of frames for tracking\n",
    "    num_frames += 1\n",
    "\n",
    "    # Display the frame with segmented hand\n",
    "    cv2.imshow(\"Finger Count\", frame_copy)\n",
    "\n",
    "\n",
    "    # Close windows with Esc\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
